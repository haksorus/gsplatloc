{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0-LmeiloOQFI"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download COCO_2017 and sample 20k images (highest resolution ones)"
      ],
      "metadata": {
        "id": "sA8GqeiqlF99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU5fwAjdJ1m1"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone --recursive https://github.com/verlab/accelerated_features.git\n",
        "!pip install kornia==0.6.12 --no-deps\n",
        "!pip install -r accelerated_features/requirements.txt --no-deps\n",
        "\n",
        "#Download precomputed coco-20k used in the paper.\n",
        "#Please refer to https://cocodataset.org/#home for the original, complete dataset.\n",
        "!gdown '1ijYsPq7dtLQSl-oEsUOGH1fAy21YLc7H'\n",
        "!unzip -qq coco_20k.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you want to build COCO_20k from scratch, try this below."
      ],
      "metadata": {
        "id": "0-LmeiloOQFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://images.cocodataset.org/zips/train2017.zip #18 GB images\n",
        "# !unzip train2017.zip\n",
        "# !rm train2017.zip\n",
        "\n",
        "# import glob\n",
        "# import random\n",
        "# import cv2\n",
        "# import os\n",
        "# import tqdm\n",
        "\n",
        "# files = sorted(glob.glob('/content/train2017/*.jpg'))\n",
        "\n",
        "# !mkdir -p /content/coco_20k\n",
        "\n",
        "# random.seed(1111)\n",
        "# random.shuffle(files)\n",
        "\n",
        "# max_imgs = 20_000\n",
        "# cnt = 0\n",
        "\n",
        "# for f in files:\n",
        "#     with tqdm.tqdm(total=max_imgs) as pbar:\n",
        "#         im = cv2.imread(f)\n",
        "#         h, w = im.shape[:2]\n",
        "#         if w >= 600 and h >= 400:\n",
        "#             cv2.imwrite('/content/coco_20k/' + os.path.basename(f), im)\n",
        "#             cnt+=1\n",
        "#             pbar.update(1)\n",
        "\n",
        "#             if cnt >= max_imgs:\n",
        "#                 break\n"
      ],
      "metadata": {
        "id": "miB7u24KKJXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train XFeat on COCO_20k (Synthetic training)\n",
        "For demonstration purposes we start to train XFeat from scratch with synthetic data only."
      ],
      "metadata": {
        "id": "VDSpQtdZlQk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/ckpts"
      ],
      "metadata": {
        "id": "z3U4MZXqlPmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd accelerated_features\n",
        "!python3 -m modules.training.train --training_type xfeat_synthetic --synthetic_root_path /content/coco_20k --ckpt_save_path /content/ckpts"
      ],
      "metadata": {
        "id": "nOP_BRppLrWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}